{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a17586",
   "metadata": {},
   "source": [
    "# Preprocessing of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec932fe6",
   "metadata": {},
   "source": [
    "Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d5a413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "%store -r mortaldict\n",
    "%store -r goddict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f066eb31",
   "metadata": {},
   "source": [
    "First, we import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d1bf626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[313] “So do not thou, my friend, wander long far from home, leaving thy wealth behind thee and men in thy house so insolent, lest they divide and devour all thy wealth, and thou shalt have gone on a fruitless journey. But to Menelaus I bid and command thee to go, for he has but lately come from a strange land, from a folk whence no one would hope in his heart to return, whom the storms had once driven astray into a sea so great, whence the very birds do not fare in the space of a year, so great is it and terrible. But now go thy way with thy ship and thy comrades, or, if thou wilt go by land, here are chariot and horses at hand for thee, and here at thy service are my sons, who will be thy guides to goodly Lacedaemon, where lives fair-haired Menelaus. And do thou beseech him thyself that he may tell thee the very truth. A lie will be not utter, for he is wise indeed.”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"homer_text_file.txt\",\"r\",encoding='utf-8') as f:\n",
    "    data = f.readlines()\n",
    "    \n",
    "print(data[700])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777c05e5",
   "metadata": {},
   "source": [
    "We split the data into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ded8a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Howbeit Poseidon had gone among the far-off Ethiopians—the Ethiopians who dwell sundered in twain, the farthermost of men, some where Hyperion sets and some where he rises, there to receive a hecatomb of bulls and rams, and there he was taking his joy, sitting at the feast; but the other gods were gathered together in the halls of Olympian Zeus.', \"[28] Among them the father of gods and men was first to speak, for in his heart he thought of noble Aegisthus, whom far-famed Orestes, Agamemnon's son, had slain.\", 'Thinking on him he spoke among the immortals, and said: “Look you now, how ready mortals are to blame the gods.', 'It is from us, they say, that evils come, but they even of themselves, through their own blind folly, have sorrows beyond that which is ordained.', 'Even as now Aegisthus, beyond that which was ordained, took to himself the wedded wife of the son of Atreus, and slew him on his return, though well he knew of sheer destruction, seeing that we spake to him before, sending Hermes, the keen-sighted Argeiphontes, that he should neither slay the man nor woo his wife; for from Orestes shall come vengeance for the son of Atreus when once he has come to manhood and longs for his own land.']\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for par in data:\n",
    "    if par == '\\n':\n",
    "        continue\n",
    "    senttemp = sent_tokenize(par)\n",
    "    sentences = sentences +senttemp\n",
    "\n",
    "print(sentences[100:105])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7817802b",
   "metadata": {},
   "source": [
    "Now, we tokenize the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6394b7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'heart', ',', 'and', 'as', 'I', 'think', 'it', 'shall', 'be', 'brought', 'to', 'pass', ',', 'though', 'I', 'am', 'in', 'no', 'wise', 'a', 'soothsayer', ',', 'nor', 'one', 'versed', 'in', 'the', 'signs', 'of', 'birds', '.', 'Not', 'much', 'longer', 'shall', 'he', 'be', 'absent', 'from', 'his', 'dear', 'native', 'land', ',', 'no', ',', 'not', 'though', 'bonds', 'of', 'iron', 'hold', 'him', '.', 'He', 'will', 'contrive', 'a', 'way', 'to', 'return', ',', 'for', 'he', 'is', 'a', 'man', 'of', 'many', 'devices', '.', 'But', 'come', ',', 'tell', 'me', 'this', 'and', 'declare', 'it', 'truly', ',', 'whether', 'indeed', ',', 'tall', 'as', 'thou', 'art', ',', 'thou', 'art', 'the', 'son', 'of', 'Odysseus', 'himself', '.', 'Wondrously']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for sent in sentences:\n",
    "    wordstemp = word_tokenize(sent)\n",
    "    words = words + wordstemp\n",
    "    \n",
    "print(words[3000:3100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72df7e92",
   "metadata": {},
   "source": [
    "Now, we PoS tag the data, so that lemmatization is easier, and names of characters can be identified more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e774e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whether', 'IN'), ('indeed', 'RB'), (',', ','), ('tall', 'JJ'), ('as', 'IN'), ('thou', 'JJ'), ('art', 'NN'), (',', ','), ('thou', 'JJ'), ('art', 'VBP'), ('the', 'DT'), ('son', 'NN'), ('of', 'IN'), ('Odysseus', 'NNP'), ('himself', 'PRP'), ('Wondrously', 'RB'), ('like', 'IN'), ('his', 'PRP$'), ('are', 'VBP'), ('thy', 'JJ'), ('head', 'NN'), ('and', 'CC'), ('beautiful', 'JJ'), ('eyes', 'NNS'), (';', ':'), ('for', 'IN'), ('full', 'JJ'), ('often', 'RB'), ('did', 'VBD'), ('we', 'PRP'), ('consort', 'VB'), ('with', 'IN'), ('one', 'CD'), ('another', 'DT'), ('before', 'IN'), ('he', 'PRP'), ('embarked', 'VBD'), ('for', 'IN'), ('the', 'DT'), ('land', 'NN'), ('of', 'IN'), ('Troy', 'NNP'), (',', ','), ('whither', 'JJR'), ('others', 'NNS'), (',', ','), ('too', 'RB'), (',', ','), ('the', 'DT'), ('bravest', 'JJS'), ('of', 'IN'), ('the', 'DT'), ('Argives', 'NNP'), (',', ','), ('went', 'VBD'), ('in', 'IN'), ('their', 'PRP$'), ('hollow', 'JJ'), ('ships', 'NNS'), ('But', 'CC'), ('since', 'IN'), ('that', 'DT'), ('day', 'NN'), ('neither', 'DT'), ('have', 'VBP'), ('I', 'PRP'), ('seen', 'VBN'), ('Odysseus', 'NNP'), (',', ','), ('nor', 'CC'), ('he', 'PRP'), ('me', 'PRP'), ('”', 'VB'), ('[', 'JJ'), ('213', 'CD'), (']', 'NN'), ('Then', 'RB'), ('wise', 'VB'), ('Telemachus', 'NNP'), ('answered', 'VBD'), ('her', 'PRP$'), (':', ':'), ('“', 'NN'), ('Therefore', 'NNP'), ('of', 'IN'), ('a', 'DT'), ('truth', 'NN'), (',', ','), ('stranger', 'NN'), (',', ','), ('will', 'MD'), ('I', 'PRP'), ('frankly', 'RB'), ('tell', 'VBP'), ('thee', 'RB'), ('all', 'DT'), ('My', 'PRP$'), ('mother', 'NN'), ('says', 'VBZ'), ('that', 'IN')]\n"
     ]
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(words)\n",
    "\n",
    "tagged_filtered = []\n",
    "for wordtag in tagged:\n",
    "    if wordtag[1] == '.':\n",
    "        continue\n",
    "    else: tagged_filtered.append(wordtag)\n",
    "        \n",
    "print(tagged_filtered[3000:3100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55514abb",
   "metadata": {},
   "source": [
    "Next, we lemmatize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "860551d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whether', 'IN'), ('indeed', 'RB'), (',', ','), ('tall', 'JJ'), ('a', 'IN'), ('thou', 'JJ'), ('art', 'NN'), (',', ','), ('thou', 'JJ'), ('art', 'VBP'), ('the', 'DT'), ('son', 'NN'), ('of', 'IN'), ('Odysseus', 'NNP'), ('himself', 'PRP'), ('Wondrously', 'RB'), ('like', 'IN'), ('his', 'PRP$'), ('be', 'VBP'), ('thy', 'JJ'), ('head', 'NN'), ('and', 'CC'), ('beautiful', 'JJ'), ('eye', 'NNS'), (';', ':'), ('for', 'IN'), ('full', 'JJ'), ('often', 'RB'), ('do', 'VBD'), ('we', 'PRP'), ('consort', 'VB'), ('with', 'IN'), ('one', 'CD'), ('another', 'DT'), ('before', 'IN'), ('he', 'PRP'), ('embark', 'VBD'), ('for', 'IN'), ('the', 'DT'), ('land', 'NN'), ('of', 'IN'), ('Troy', 'NNP'), (',', ','), ('whither', 'JJR'), ('others', 'NNS'), (',', ','), ('too', 'RB'), (',', ','), ('the', 'DT'), ('brave', 'JJS'), ('of', 'IN'), ('the', 'DT'), ('Argives', 'NNP'), (',', ','), ('go', 'VBD'), ('in', 'IN'), ('their', 'PRP$'), ('hollow', 'JJ'), ('ship', 'NNS'), ('But', 'CC'), ('since', 'IN'), ('that', 'DT'), ('day', 'NN'), ('neither', 'DT'), ('have', 'VBP'), ('I', 'PRP'), ('see', 'VBN'), ('Odysseus', 'NNP'), (',', ','), ('nor', 'CC'), ('he', 'PRP'), ('me', 'PRP'), ('”', 'VB'), ('[', 'JJ'), ('213', 'CD'), (']', 'NN'), ('Then', 'RB'), ('wise', 'VB'), ('Telemachus', 'NNP'), ('answer', 'VBD'), ('her', 'PRP$'), (':', ':'), ('“', 'NN'), ('Therefore', 'NNP'), ('of', 'IN'), ('a', 'DT'), ('truth', 'NN'), (',', ','), ('stranger', 'NN'), (',', ','), ('will', 'MD'), ('I', 'PRP'), ('frankly', 'RB'), ('tell', 'VBP'), ('thee', 'RB'), ('all', 'DT'), ('My', 'PRP$'), ('mother', 'NN'), ('say', 'VBZ'), ('that', 'IN')]\n"
     ]
    }
   ],
   "source": [
    "# Reference for lemmatizing: https://stackoverflow.com/questions/15586721/wordnet-lemmatization-and-pos-tagging-in-python\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized = []\n",
    "for wordtag in tagged_filtered:\n",
    "    tag = ''\n",
    "    if wordtag[1][0:2] ==  'NN':\n",
    "        tag =  'n'\n",
    "    elif wordtag[1][0:2] ==  'VB':\n",
    "        tag =  'v'\n",
    "    elif wordtag[1][0:2] ==  'JJ':\n",
    "        tag =  'a'\n",
    "    elif wordtag[1][0:2] ==  'RB':\n",
    "        tag =  'r'\n",
    "        \n",
    "    # use postag if it exists in the wordnetlemmatizer\n",
    "    if tag == '': lemma = lemmatizer.lemmatize(wordtag[0])\n",
    "    else: lemma = lemmatizer.lemmatize(wordtag[0], pos=tag)\n",
    "        \n",
    "    lemmatized.append((lemma, wordtag[1]))\n",
    "    \n",
    "print(lemmatized[3000:3100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0daf3e",
   "metadata": {},
   "source": [
    "Next, we go through the data and print all the proper nouns that aren't in the dictionaries. If they are not and they refer to names of characters that are either Olympian gods or mortals, we add them to the dictionaries in the file characterdicts.ipynb. We do this only for names that occur multiple times in the book, since adding all names is not realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2844260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOMER 52\n",
      "ODYSSEY 100\n",
      "BOOK 650\n",
      "Theoi 75\n",
      "Classical 52\n",
      "Texts 75\n",
      "Library 127\n",
      "Toggle 25\n",
      "Project 50\n",
      "LIBRARY 50\n",
      "HOME 25\n",
      "GREEK 50\n",
      "MYTHOLOGY 25\n",
      "GODS 25\n",
      "Olympian 30\n",
      "Gods 275\n",
      "Primordial 25\n",
      "Titan 25\n",
      "Sky 25\n",
      "Sea 25\n",
      "Rustic 25\n",
      "Underworld 50\n",
      "Daemones-Spirits 25\n",
      "Nymphs 27\n",
      "> 125\n",
      "BESTIARY 25\n",
      "HEROES 25\n",
      "MISCELLANY 25\n",
      "Spirits 50\n",
      "Monsters 50\n",
      "A-Z 25\n",
      "Family 25\n",
      "Tree 25\n",
      "Legendary 50\n",
      "Tribes 25\n",
      "Creatures 25\n",
      "Star 25\n",
      "Myths 50\n",
      "Plant 25\n",
      "Flower 25\n",
      "GALLERY 25\n",
      "Homer 77\n",
      "Odyssey 56\n",
      "Book 25\n",
      "Ionia 2\n",
      "Greeks 27\n",
      "Iliad 27\n",
      "C8th 2\n",
      "C7th 2\n",
      "B.C 2\n",
      "Murray 4\n",
      "A 53\n",
      "T. 27\n",
      "Loeb 4\n",
      "Volumes 2\n",
      "Cambridge 2\n",
      "MA 2\n",
      "Harvard 2\n",
      "University 2\n",
      "Press 2\n",
      "London 2\n",
      "William 2\n",
      "Heinemann 2\n",
      "Ltd. 2\n",
      "Amazon.com 2\n",
      "Greek 27\n",
      "Dimock 2\n",
      "Shewring 2\n",
      "Theoi.com 2\n",
      "THE 25\n",
      "CONTENTS 25\n",
      "Telemachus 371\n",
      "Penelope 160\n",
      "Departure 25\n",
      "Nestor 77\n",
      "Returns 50\n",
      "Menelaus 90\n",
      "Calypso 50\n",
      "Raft 25\n",
      "Naucicaa 25\n",
      "Arete 39\n",
      "Games 25\n",
      "Feast 25\n",
      "Lotus-Eaters 25\n",
      "Cyclops 45\n",
      "Laestrygones 25\n",
      "Circe 70\n",
      "Scylla 37\n",
      "Helius 28\n",
      "Return 50\n",
      "Ithaca 129\n",
      "Eumaeus 94\n",
      "Odyseus 25\n",
      "Beggar 50\n",
      "Contest 50\n",
      "Suitors 75\n",
      "Slaying 25\n",
      "Dead 50\n",
      "BY 25\n",
      "A. 25\n",
      "MURRAY 25\n",
      "] 68\n",
      "Tell 6\n",
      "O 26\n",
      "Troy 68\n",
      "Many 2\n",
      "Helios 18\n",
      "Hyperion 9\n",
      "Howbeit 17\n",
      "Ethiopians—the 2\n",
      "Aegisthus 26\n",
      "Orestes 7\n",
      "Agamemnon 75\n",
      "Look 2\n",
      "Atreus 53\n",
      "Father 23\n",
      "Cronos 34\n",
      "Atlas 3\n",
      "Did 6\n",
      "Argives 17\n",
      "Wherefore 9\n",
      "” 12\n",
      "My 20\n",
      "Nay 122\n",
      "Polyphemus 5\n",
      "Cyclopes 12\n",
      "Thoosa 2\n",
      "Phorcys 4\n",
      "Ogygia 7\n",
      "Sparta 10\n",
      "Pylos 41\n",
      "So 89\n",
      "Olympus 21\n",
      "Mentes 4\n",
      "Hail 5\n",
      "Phemius 6\n",
      "Dear 11\n",
      "Therefore 10\n",
      "Anchialus 5\n",
      "Rheithron 2\n",
      "Neion 3\n",
      "Laertes 53\n",
      "Ah 23\n",
      "Angered 2\n",
      "Stranger 25\n",
      "Same 7\n",
      "Zacynthus— 2\n",
      "Thou 34\n",
      "Ephyre 3\n",
      "Ilus 4\n",
      "Mermerus 2\n",
      "Would 3\n",
      "Come 24\n",
      "Achaean 14\n",
      "First 15\n",
      "Stay 3\n",
      "Achaeans—the 2\n",
      "Hellas 6\n",
      "Prepare 2\n",
      "Antinous 54\n",
      "Eupeithes 14\n",
      "May 10\n",
      "Thinkest 2\n",
      "Straightway 20\n",
      "Achaeans 7\n",
      "Eurymachus 34\n",
      "Polybus 13\n",
      "Taphos 2\n",
      "Taphians. 2\n",
      "Eurycleia 25\n",
      "Ops 4\n",
      "Peisenor 5\n",
      "SEARCH 25\n",
      "THEOI 25\n",
      "CLASSICAL 25\n",
      "TEXTS 25\n",
      "Aeschylus 175\n",
      "Eumenides 25\n",
      "Libation 25\n",
      "Bearers 25\n",
      "Prometheus 25\n",
      "Bound 25\n",
      "Seven 25\n",
      "Against 25\n",
      "Thebes 26\n",
      "Suppliant 25\n",
      "Women 25\n",
      "Fragments 125\n",
      "Alcman 25\n",
      "Apollodorus 25\n",
      "Apollonius 25\n",
      "Rhodius 25\n",
      "Argonautica 50\n",
      "Aratus 25\n",
      "Soli 25\n",
      "Phaenomena 25\n",
      "Bion 25\n",
      "Poems 75\n",
      "Callimachus 25\n",
      "Hymns 75\n",
      "Callistratus 25\n",
      "Descriptions 25\n",
      "Claudian 50\n",
      "Gigantomachia 25\n",
      "Rape 50\n",
      "Proserpine 25\n",
      "Clement 50\n",
      "Exhortation 25\n",
      "Recognitions 25\n",
      "Colluthus 25\n",
      "Helen 46\n",
      "Dares 25\n",
      "Phrygius 25\n",
      "Dictys 25\n",
      "Cretensis 25\n",
      "Diodorus 25\n",
      "Siculus 25\n",
      "History 25\n",
      "Epic 25\n",
      "Cycle 25\n",
      "Fulgentius 25\n",
      "Mythologies 25\n",
      "Lyric 25\n",
      "Hesiod 100\n",
      "Shield 25\n",
      "Theogony 25\n",
      "Works 25\n",
      "Days 25\n",
      "Homeric 25\n",
      "Hyginus 50\n",
      "Astronomica 25\n",
      "Fabulae 25\n",
      "Lucian 50\n",
      "Dialogues 50\n",
      "Lycophron 25\n",
      "Alexandra 25\n",
      "Moschus 25\n",
      "Nonnus 25\n",
      "Dionysiaca 25\n",
      "Orphic 25\n",
      "Ovid 75\n",
      "Fasti 25\n",
      "Heroides 25\n",
      "Metamorphoses 25\n",
      "Parthenius 25\n",
      "Love 25\n",
      "Romances 25\n",
      "Pattern 25\n",
      "Pausanias 25\n",
      "Description 25\n",
      "Greece 25\n",
      "Philostratus 50\n",
      "Elder 25\n",
      "Imagines 50\n",
      "Younger 25\n",
      "Plutarch 50\n",
      "Life 25\n",
      "Parallel 25\n",
      "Stories 25\n",
      "Quintus 25\n",
      "Smyrnaeus 25\n",
      "Fall 25\n",
      "Seneca 225\n",
      "Furens 25\n",
      "Oetaeus 25\n",
      "Medea 25\n",
      "Phaedra 26\n",
      "Phoenissae 25\n",
      "Thyestes 26\n",
      "Troades 25\n",
      "Statius 50\n",
      "Achilleid 25\n",
      "Thebaid 25\n",
      "Theocritus 25\n",
      "Idylls 25\n",
      "Tryphiodorus 25\n",
      "Taking 25\n",
      "Ilios 43\n",
      "Tzetzes 25\n",
      "Chiliades 25\n",
      "Valerius 25\n",
      "Flaccus 25\n",
      "Virgil 75\n",
      "Aeneid 25\n",
      "Eclogues 25\n",
      "Georgics 25\n",
      "RECENT 25\n",
      "ARTICLES 25\n",
      "Who 26\n",
      "Was 26\n",
      "Warrior 25\n",
      "© 25\n",
      "Copyright 25\n",
      "Aaron 25\n",
      "J. 25\n",
      "Atsma 25\n",
      "New 25\n",
      "Zealand 25\n",
      "Contact 25\n",
      "Us 25\n",
      "Soon 3\n",
      "Antiphus 2\n",
      "Eurynomus 2\n",
      "Hearken 8\n",
      "Old 12\n",
      "Alcmene 2\n",
      "Mycene 2\n",
      "Halitherses 4\n",
      "Mastor 2\n",
      "Aye 34\n",
      "Mentor 20\n",
      "Never 2\n",
      "Lo 22\n",
      "Nurse 3\n",
      "Zeus-born 5\n",
      "Whither 4\n",
      "Furthermore 2\n",
      "Noemon 3\n",
      "Phronius 3\n",
      "Thus 26\n",
      "West 12\n",
      "Neleus 12\n",
      "Earth-shaker 8\n",
      "Forth 3\n",
      "Peisistratus 12\n",
      "Thrasymedes 4\n",
      "Gerenia 11\n",
      "Whence 2\n",
      "Priam 8\n",
      "Aias 7\n",
      "Patroclus 5\n",
      "Antilochus 6\n",
      "Amazement 2\n",
      "Tydeus 3\n",
      "Lesbos 3\n",
      "Chios 3\n",
      "Euboea 2\n",
      "Argos 15\n",
      "“ 80\n",
      "Idomeneus 8\n",
      "Crete 14\n",
      "Friend 11\n",
      "Clytemnestra 3\n",
      "Athens 4\n",
      "Malea 4\n",
      "Wind 32\n",
      "Thither 6\n",
      "Egypt 13\n",
      "Lacedaemon 9\n",
      "Well 3\n",
      "Hades 36\n",
      "Echephron 2\n",
      "Stratius 2\n",
      "Aretus 2\n",
      "Quickly 3\n",
      "Pherae 3\n",
      "Diocles 2\n",
      "Ortilochus 3\n",
      "Alpheus 2\n",
      "Him 15\n",
      "Myrmidons 2\n",
      "Megapenthes 4\n",
      "Eteoneus 3\n",
      "Boethous 3\n",
      "Son 13\n",
      "Cyprus 5\n",
      "Phoenicia 3\n",
      "Libya 2\n",
      "Phylo 2\n",
      "—a 3\n",
      "Dawn 30\n",
      "Whoso 2\n",
      "Trojan 2\n",
      "Ere 4\n",
      "Deiphobus 2\n",
      "Thrice 4\n",
      "Argive 5\n",
      "Philomeleides 2\n",
      "Therein 10\n",
      "Proteus 2\n",
      "Aegyptus 6\n",
      "Gyrae 2\n",
      "Rhadamanthus 2\n",
      "Ocean 2\n",
      "Hephaestus 19\n",
      "Phaedimus 2\n",
      "Elis 5\n",
      "Samos 3\n",
      "Medon 10\n",
      "Herald 3\n",
      "Cruel 4\n",
      "Dolius 12\n",
      "Arceisius 5\n",
      "Good 4\n",
      "Didst 3\n",
      "Scheria 4\n",
      "ye 5\n",
      "Ortygia 2\n",
      "Unhappy 2\n",
      "Verily 14\n",
      "East 4\n",
      "South 7\n",
      "North 13\n",
      "Peleus 13\n",
      "Ino 2\n",
      "Woe 3\n",
      "Haply 2\n",
      "Nausithous 5\n",
      "Alcinous 63\n",
      "Nausicaa 13\n",
      "Thy 6\n",
      "Full 3\n",
      "Stand 2\n",
      "Rouse 2\n",
      "Better 2\n",
      "Sit 4\n",
      "Apeire 2\n",
      "Sir 7\n",
      "Go 6\n",
      "Periboea 2\n",
      "Rhexenor 3\n",
      "Echeneus 2\n",
      "Laodamas 9\n",
      "Pontonous 5\n",
      "Whomsoever 2\n",
      "Yea 9\n",
      "Hard 5\n",
      "Gaea 2\n",
      "Demodocus 11\n",
      "Pytho 2\n",
      "Elatreus 2\n",
      "Amphialus 2\n",
      "Euryalus 6\n",
      "Halius 2\n",
      "Clytoneus 2\n",
      "Be 11\n",
      "Eurytus 5\n",
      "Lemnos 3\n",
      "Lord 6\n",
      "Bring 3\n",
      "Phaeacians 2\n",
      "Neriton 2\n",
      "Dulichium 8\n",
      "Zacynthus 2\n",
      "Aeaea 2\n",
      "Cicones 2\n",
      "Ismarus 2\n",
      "Lotus-eaters 2\n",
      "Thence 2\n",
      "Noman 5\n",
      "’ 7\n",
      "Aeolus 6\n",
      "Hippotas 2\n",
      "Telepylus 2\n",
      "Aeetes 2\n",
      "Oceanus 14\n",
      "Eurylochus 12\n",
      "Dost 7\n",
      "Persephone 9\n",
      "Theban 6\n",
      "Teiresias 15\n",
      "Erebus 5\n",
      "Elpenor 3\n",
      "Perimedes 2\n",
      "Aeaean 4\n",
      "Fulfil 2\n",
      "Autolycus 18\n",
      "Thrinacia 4\n",
      "Poseidon—a 2\n",
      "Art 4\n",
      "Achaea 4\n",
      "Cretheus 2\n",
      "Enipeus 2\n",
      "Shaker 2\n",
      "Pelias 2\n",
      "Amphion 2\n",
      "Zethus 2\n",
      "Thebe 4\n",
      "Amphitryon 2\n",
      "Iasus 2\n",
      "Orchomenus 2\n",
      "Phylace 2\n",
      "Tyndareus 3\n",
      "Castor 2\n",
      "Ossa 2\n",
      "Minos 4\n",
      "Aeacus 2\n",
      "Alone 2\n",
      "Telamon 2\n",
      "Peirithous 3\n",
      "Sirens 8\n",
      "Charybdis 8\n",
      "Wilt 2\n",
      "Lampetie 2\n",
      "Therewith 5\n",
      "Fare 2\n",
      "Naiads 2\n",
      "Cease 2\n",
      "Sidon 2\n",
      "Ye 2\n",
      "Truly 2\n",
      "Eat 2\n",
      "Pheidon 2\n",
      "Dodona 2\n",
      "Mesaulius 2\n",
      "Beware 3\n",
      "Awake 2\n",
      "Up 2\n",
      "Melampus 2\n",
      "Mantius 2\n",
      "Oicles 2\n",
      "Amphiaraus 2\n",
      "Polypheides 2\n",
      "Cleitus 2\n",
      "Theoclymenus 8\n",
      "Than 2\n",
      "Nevertheless 2\n",
      "Peiraeus 7\n",
      "Clytius 2\n",
      "Zacynthus—and 2\n",
      "Amphinomus 13\n",
      "Nisus 3\n",
      "Aretias 2\n",
      "Daughter 4\n",
      "Honored 5\n",
      "Polyctor 3\n",
      "Melanthius 16\n",
      "Shame 2\n",
      "King 3\n",
      "Irus 12\n",
      "Echetus 3\n",
      "Eurydamas 2\n",
      "Peisander 3\n",
      "Melantho 3\n",
      "Wretched 2\n",
      "Strange 4\n",
      "Abuse 2\n",
      "Lady 3\n",
      "Parnassus 6\n",
      "Mother 2\n",
      "Pandareus 2\n",
      "Itylus 2\n",
      "Philoetius 5\n",
      "Hapless 2\n",
      "Neatherd 2\n",
      "Ctesippus 4\n",
      "Agelaus 8\n",
      "God 2\n",
      "Quick 2\n",
      "Iphitus 5\n",
      "Messene 2\n",
      "Leiodes 3\n",
      "Damastor 3\n",
      "Amphimedon 6\n",
      "Demoptolemus 2\n",
      "Wife 2\n"
     ]
    }
   ],
   "source": [
    "non_occuring = {}\n",
    "\n",
    "mortals = mortaldict\n",
    "gods = goddict\n",
    "\n",
    "for wordtag in lemmatized:\n",
    "    \n",
    "    # Only look at proper nouns\n",
    "    if wordtag[1] == 'NNP':\n",
    "        \n",
    "        # Binary to indicate if the word has been found\n",
    "        filled_in = 0\n",
    "        \n",
    "        # Go through mortaldict\n",
    "        for idx, vals in enumerate(mortals.values()):\n",
    "            if wordtag[0] in vals[0]:\n",
    "                filled_in = 1\n",
    "                break\n",
    "                \n",
    "        # If word hasn't been found in mortaldict, go through goddict\n",
    "        if filled_in == 0:\n",
    "            for idx, vals in enumerate(gods.values()):\n",
    "                if wordtag[0] in vals[0]:\n",
    "                    filled_in = 1\n",
    "                    break\n",
    "        \n",
    "        # Print word if it hasn't been found at all\n",
    "        if filled_in == 0:\n",
    "            if wordtag[0] in non_occuring.keys():\n",
    "                non_occuring[wordtag[0]] += 1\n",
    "            else: non_occuring[wordtag[0]] = 1\n",
    "\n",
    "for key in non_occuring.keys():\n",
    "    if non_occuring[key] != 1:\n",
    "        print(key, non_occuring[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b80de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
